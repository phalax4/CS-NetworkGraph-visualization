{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Node, Relationship, Graph\n",
    "directory = \"cs-network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"http://neo4j:toor@localhost:7474/db/data\")\n",
    "graph.cypher.execute(\n",
    "        \"MATCH (n) DETACH DELETE (n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    graph.schema.create_uniqueness_constraint(\"Page\", \"name\")\n",
    "except:\n",
    "    print(\"Constraint already there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(directory + \"/page_rank.txt\",'r')\n",
    "pgr_data = {}\n",
    "total = 0.0\n",
    "for line in f:\n",
    "    t = line.split(\" \")\n",
    "    total+=float(t[1].rstrip())\n",
    "    pgr_data[str(t[0])] = float(t[1].rstrip())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"cs-network/linkToPageNum.txt\",'r')\n",
    "url_to_alias = {}\n",
    "alias_to_url = {}\n",
    "for line in f:\n",
    "    t = line.split(\",\")\n",
    "    if t[1].rstrip() in alias_to_url:\n",
    "        print(\"Error\")\n",
    "    alias_to_url[t[1].rstrip()] = t[0]\n",
    "    url_to_alias[t[0]] = t[1].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(directory + \"/graph.txt\", 'r')\n",
    "graph_data = {}\n",
    "for line in f:\n",
    "    if line.strip() == \"\":\n",
    "        continue\n",
    "    p = line[:line.index(\"-\")]\n",
    "    qList = line[line.index(\">\") + 1:][1:-2].replace(\" \", \"\").split(\",\")\n",
    "    a = list(graph.merge(\"Page\", \"name\", p))[0]\n",
    "    for q in qList:\n",
    "        if q != \"\":\n",
    "            b = list(graph.merge(\"Page\", \"name\", q))[0]\n",
    "            graph.create_unique(Relationship(a, \"LINKS_TO\", b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "html_doc = \"\"\n",
    "with urllib.request.urlopen('http://www.cs.utexas.edu/users/mooney/ir-course/students.html') as response:\n",
    "        html_doc = response.read()\n",
    "                           \n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "student_links = []\n",
    "for a in soup.find_all('a', href=True):\n",
    "    student_links.append(a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MATCH (m:Page)<-[:LINKS_TO]-(a:Page) RETURN m.name as name, collect(a.name) as links\"\n",
    "results = graph.cypher.execute(\n",
    "        \"MATCH (m:Page)<-[:LINKS_TO]-(a:Page) \"\n",
    "        \"RETURN m.name as name, collect(a.name) as links\")\n",
    "#for i in results:\n",
    "    #print(i)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint\n",
    "nodes = []\n",
    "rels = []\n",
    "i = 0\n",
    "for name, links in results:\n",
    "    nodes.append({\"id\": name, \"rank\": pgr_data[name + \".html\"], \"label\": \"page\", \"group\": randint(1, 10), \"url\": alias_to_url[name]})\n",
    "    target = name\n",
    "    i += 1\n",
    "    for linkName in links:\n",
    "        actor = {\"name\": linkName, \"label\": \"page\"}\n",
    "        try:\n",
    "            source = nodes.index(actor)\n",
    "        except ValueError:\n",
    "            nodes.append(actor)\n",
    "            source = i\n",
    "            i += 1\n",
    "        rels.append({\"source\": linkName, \"target\": target})\n",
    "rr = {\"nodes\": nodes, \"links\": rels}\n",
    "f = open(\"pagerank.json\",'w')\n",
    "f.write(json.dumps(rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify student pages\n",
    "#Identify page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
