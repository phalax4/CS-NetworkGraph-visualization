<base href="https://www.cs.utexas.edu/~gouda/cs356summer09/midterm2/">
------------------------------------------------------------------------------
Mohamed G. Gouda                                                CS 356
Summer 2009                                                 	Midterm 2
------------------------------------------------------------------------------
Open Book                                                       75 minutes
------------------------------------------------------------------------------
1. (10 points)

Consider a block that consists of m*n data bits followed by n parity bits. The 
corruption burst in this block is called persistent if and only if it satisfies
the following condition:

       If a bit in the block is corrupted, then every bit that follows
       this bit in the block is also corrupted.

What is the length of the longest persistent corruption burst that can be
detected by the corruption detection protocol in Section 6.1? Explain your 
answer. 

Solution:

The length of the longest persistent corruption burst that can be detected =
	if m is odd -> (m+1)*n-1
	[] m is even -> (m+1)*n
	fi
This guarantees that the corruption burst has at least one column where the 
number of corrupted bits is odd.
------------------------------------------------------------------------------
2. (10 points)

Consider a protocol where a process p continuously sends data messages to a
process q. Assume that the sent data messages from p to q can be corrupted
according to the following two rules:

	1. If a data message is corrupted, then the corruption burst 
	   in the message is of length at most 20 bits.

	2. In every sequence of 4 consecutive data messages, there exists 
	   a subsequence of 2 consecutive data messages that contains all 
	   the corrupted messages in the sequence. 
	    
In order for q to forward recover from message corruption, every sent data 
message consists of three fields: a sequence number, a text, and a checksum. 
The checksum in a data message is used by process q to detect whether or not 
the message has been corrupted. Process q discards every corrupted message, 
thus transforming the occurrence of message corruption into an occurrence of 
message loss. Anticipating the possibility of message loss, process p sends 
every data message twice, according to the protocol for forward recovery from 
2-bounded loss. What is the smallest number of bits in each of three fields of
a data message? Explain your answer.

Solution:

The smallest # bits in the sequence number field = 2*n - 1  =  2 bits
(since the loss is 2-bounded, and so n=2)

The smallest # bits in the text field = m*20 - 2 = 18 bits 
(since m >= 1)

The smallest # bits in the checksum field = 20 bits 
(since the corruption burst to be detected is of length at most 20)
------------------------------------------------------------------------------
