<base href="http://www.cs.utexas.edu/users/kuipers/cs343-S08.html">
<html>
<head>
<title>CS 343: Artificial Intelligence</title>
<link rel=stylesheet href="/~kuipers/styles/bibliographies.css" type="text/css">
</head>

<body>


<h1>CS 343:  Artificial Intelligence</h1>

 <ul>
  <li>  Spring 2008.  (unique #55635)
  <li>  When/Where:  MW 10:30 - 12:00, PAI 3.14
  <li>  Professor <a href="index.html">Benjamin Kuipers</a>
        (kuipers@cs.utexas.edu)
    <ul>
     <li>  Office hours:  MW 9:30 - 10:30 am, CSA 1.120A  <br>
            (CSA (Computer Science Annex) is the temporary building in front of ENS.)
    </ul>
  <li>  Teaching Assistant:  Vinod Valsalam (vkv@cs.utexas.edu)
    <ul>
     <li>  Office hours:  Monday 1:30 - 2:30 pm; Thursday 2:00 - 3:00 pm
     <li>  Where:  ENS 31NQ Desk #3
    </ul> <p>

  <li>  <b>Prerequisites</b>:  the following courses, with a grade of C or better
        in each:  CS 310 or 310H, CS 336 or 336H, and M 408D or 408M. 
  <li>  <b>Textbook</b>:  
        <a href="http://aima.cs.berkeley.edu">
        <i>Artificial Intelligence:  A Modern Approach</i></a>, Second Edition,
        by Stuart Russell and Peter Norvig (Prentice Hall, 2003). <p>
  <li>  This page:  
        <a href="http://www.cs.utexas.edu/users/kuipers/cs343-S08.html">
        http://www.cs.utexas.edu/users/kuipers/cs343-S08.html</a>
  <li>  Class wiki:
        <a href="http://z.cs.utexas.edu/wiki/cs343.wiki">
        http://z.cs.utexas.edu/wiki/cs343.wiki</a>
 </ul>

<p>
[<i>Various bits of this course description are still under construction.</i>]
</p>

<h2>Lecture Topics and Reading Assignments</h2>

<p>
The reading assignments are from the textbook, and should be read
<i>before</i> the corresponding class.  They average about 20 pages
per class, and should take 1-2 hours to read carefully.  (You will find
that, if you make a practice of doing the reading carefully before
each class, you will learn more, you will get a better grade, and
you will use your time and effort more efficiently and effectively.)
</p>

<hr>
<table>

<tr><td> <b>date</b>	</td><td> <b>lecture topic</b>	</td><td> 
 <b>read <i>before</i> class</b>	</td></tr>

<tr><td>	1/14	</td><td>	What is AI?	</td><td> 
	chapter 1	</td></tr>
<tr><td>	1/16	</td><td>	Agents and environments 
	</td><td>	chapter 2	</td></tr>
<tr><td>	1/21	</td><td>	(MLK holiday)	</td><td> 
		</td></tr>
<tr><td>	1/23	</td><td>	State spaces and search 
	</td><td>	chapter 3	</td></tr>
<tr><td>	1/28	</td><td>	Informed search	</td><td> 
	4.1, 4.2, 4.3, 4.6	</td></tr>
<tr><td>	1/30	</td><td>	Constraint satisfaction 
problems	</td><td>	chapter 5	</td></tr>
<tr><td>	2/4	</td><td>	Logical agents	</td><td> 
	7.1-7.5	</td></tr>
<tr><td>	2/6	</td><td>	Propositional inference 
	</td><td>	7.7, 7.8, 8.1	</td></tr>
<tr><td>	2/11	</td><td>	First-order logic 
	</td><td>	8.2, 8.3, 8.4, 8.5	</td></tr>
<tr><td>	2/13	</td><td>	First-order inference 
	</td><td>	9.1-9.4, 9.6 (+ box p.302)	</td></tr>
<tr><td>	2/18	</td><td>	Representing knowledge 
	</td><td>	10.1, 10.2, 10.3, 10.6, 10.9	</td></tr>
<tr><td>	2/20	</td><td>	Planning	</td><td> 
	11.1, 11.2, 11.3	</td></tr>
<tr><td>	2/25	</td><td>	Planning algorithms 
	</td><td>	11.4, 11.5, 11.6, 11.7	</td></tr>
<tr><td>	2/27	</td><td>	Resources and hierarchy 
	</td><td>	12.1, 12.2, 12.3	</td></tr>
<tr><td>	3/3	</td><td>	Non-deterministic 
environments	</td><td>	12.4, 12.5, 12.6, 12.8	</td></tr>
<tr><td>	3/5	</td><td>	<b>Mid-term exam</b>	</td><td> 
		</td></tr>
<tr><td>	Spring Break	</td><td>		</td><td> 
		</td></tr>
<tr><td>	3/17	</td><td>	Uncertainty	</td><td> 
	chapter 13	</td></tr>
<tr><td>	3/19	</td><td>	Bayesian networks 
	</td><td>	14.1, 14.2, 14.3, 14.7	</td></tr>
<tr><td>	3/24	</td><td>	Inference in Bayesian 
networks	</td><td>	14.4, 14.5, 14.8	</td></tr>
<tr><td>	3/26	</td><td>	Probabilistic reasoning over 
time	</td><td>	15.1, 15.2, 15.3, 15.7	</td></tr>
<tr><td>	3/31	</td><td>	Decision analysis 
	</td><td>	16.1-16.5, 16.7, 16.8	</td></tr>
<tr><td>	4/2	</td><td>	Learning decision trees 
	</td><td>	18.1, 18.2, 18.3, 18.6	</td></tr>
<tr><td>	4/7	</td><td>	Statistical learning 
	</td><td>	20.1, 20.2	</td></tr>
<tr><td>	4/9	</td><td>	Kernel methods	</td><td> 
	20.4, 20.6, 20.7, 20.8	</td></tr>
<tr><td>	4/14	</td><td>	Reinforcement learning 
	</td><td>	21.1, 21.2, 21.3, 21.6	</td></tr>
<tr><td>	4/16	</td><td>	Grounding symbols in perception 
	</td><td>	24.1, 24.5, 24.6, 24.7 	</td></tr>
<tr><td>	4/21	</td><td>	Vision 
	</td><td>	chapter 24	</td></tr>
<tr><td>	4/23	</td><td>	Robotics 
	</td><td>	chapter 25	</td></tr>
<tr><td>	4/28	</td><td>	Philosophy:  Is AI possible? 
	</td><td>	chapter 26	</td></tr>
<tr><td>	4/30	</td><td>	Philosophy:  What if we 
succeed?	</td><td>	chapter 27	</td></tr>
<tr><td>	5/8	</td><td>	<b>Final Exam</b> (2:00 - 5:00 pm) 
	</td><td>		</td></tr>
</table>


<h2>Assignments</h2>

<p>
The total credit for programming assignments will be spread across 3.5
to 4.5 assignments.  (Assignment 0 is worth 0.5; the others will be
worth 1.0.)  Programming assignments will be done in <a
href="http://www.python.org/">Python</a>.
</p>

<ul>
 <li> Assignment 0 is done by each individual.
 <li> Assignments 1-4 are done by <b>pairs</b> (or optionally, by individuals).
      <br>
      Send email to kuipers@cs and vkv@cs by February 1 saying who your partner is.
      <br>
      Each individual submits a statement describing who did what portion of the work
      on each assignment.
</ul>

<h4>Assignment Due Dates</h4>

The assignments will be turned in using the <code>turnin</code> program.
<ul>
 <li>  Assignment 0 is due at 10:00 am Monday, January 28
 <li>  Assignment 1 is due at 10:00 am Monday, February 18
 <li>  Assignment 2 is due at 10:00 am Monday, March 17
 <li>  Assignment 3 is due at 10:00 am Monday, April 7
 <li>  Assignment 4 is due at 10:00 am Monday, April 28
</ul>

<p>
Some details of exactly what will be turned in, and how it will be
graded, will be provided on the class Wiki.  Use the
information below to get started.
</p>

<h4>Assignment 0:  Hello World!</h4>

Learn and use Python:
<ul>
 <li> The <a href="http://www.python.org/">Python Official Website</a>
  <ul>
   <li>   <a href="http://docs.python.org/tut/tut.html">tutorial</a>
  </ul>
 <li> Informed opinion:  Read Eric Raymond,
      <a href="http://www.linuxjournal.com/article/3882">Why Python?</a>,
      Linux Journal, 2000.
 <li> Informed opinion:  Read Peter Norvig,
      <a href="http://www.norvig.com/python-lisp.html">Python for Lisp programmers</a>
  <ul>
   <li>  <a href="http://www.norvig.com/python-iaq.html">Infrequently Asked Questions</a>
  </ul>
 <li> Task:  Implement <a href="http://norvig.com/sudoku.html">Peter Norvig's Sudoku solver</a>
  <ul>
   <li> A good source of <a href="http://www.websudoku.com">Sudoku puzzles</a>.
   <li> A very extensive <a href="http://www.sudoku.com/forums.html">
        Sudoku Players Forum</a> set of discussion groups.
  </ul>
</ul>

<p>
You must add three switch-controlled trace messages to Peter Norvig's
Sudoku solver.
<ul>
 <li> trace1=true prints a message every time the search program selects a
hypothesis to explore, and every time the current branch fails.
 <li> trace2=true prints a message every time a cell gets a specific value.
 <li> trace3=true prints a message every time the number of candidate values
for a cell changes.
</ul>
In various combinations, these trace-switch settings should make it possible
for a viewer to get a clear picture of what the solver is doing.  (It should
be quite helpful for debugging.)
</p>

<p>
When you turn in your Python program, it will be tested on several different
puzzles, with different trace settings.
</p>

<h4>Assignment 1:  Modeling Expertise in Sudoku</h4>

<p>
When humans solve Sudoku puzzles, they typically use various sorts of
constraint propagation, resorting to limited amounts of backtracking
search only for the most difficult cases.  As a human increases in
expertise at solving Sudoku puzzles, they seem to use more and more
sophisticated types of constraint reasoning.  Your task will be to model
this.
</p>

<p>
Sudoku puzzles are often classified in four levels of difficulty.  For
example, <a href="http://www.websudoku.com">Websudoku</a> has the
levels: Easy, Medium, Hard, and Evil.  Your task will be to write four
Sudoku-solvers, with expertise at each of these levels.  That is, the
program at a given level should be able to do well on puzzles at that
level and below, and poorly at higher levels.
</p>

<p>
You may start from Peter Norvig's code, which you got running in
Assignment 0.  However, we will say that Norvig's code runs at the
"Supernatural" level of expertise, since it has little difficulty with
the supposed "hardest Sudoku puzzle".  Your top level of expertise
should be able to solve most "Evil" puzzles, but not these extremely
hard puzzles.  It is possible that you will need to change the
underlying state representation to do this assignment.
</p>


<h4>Assignment 2:  
   Implement a Simple Knowledge Representation and Inference System</h4>

<p>
You will implement a frame-based knowledge representation including a
logic programming language with both forward and backward chaining
inference rules.  You will do your implementation in Python, but the
language design is drawn from <a
href="http://www.cs.utexas.edu/~qr/algernon.html">Algernon</a>, which
is implemented in Lisp.
</p>



<h4>Assignment 3:  
   Create a Knowledge Base for UT Courses, Majors, and Graduation</h4>

<p>
You will implement an an ontology including these important sets:
Courses, Departments, Majors, Requirements, Offerings, and Students.
You will also implement necessary relations among them, and rules for
drawing the relevant inferences.  The task will be to represent the
requirements for graduating with a variety of majors (for example, the
various majors offered by the Computer Science Department), and to
check the transcript of particular students to determine whether they
have met the requirements for graduating with a particular major.
</p>




<h2>Grading</h2>

<table>
<tr><td>  Class participation:  </td><td>  10%  </td></tr>
<tr><td>  Assignments (4?):     </td><td>  40%  </td></tr>
<tr><td>  Mid-term exam:        </td><td>  20%  </td></tr>
<tr><td>  Final exam:           </td><td>  30%  </td></tr>
</table>

<p>
These may be adjusted.
Attendance will be taken in class.
</p>

<h2>Handout Slides</h2>

<ul>

<li> (1-14) <a href="slides/L1-Intro.pdf">L1-Intro.pdf</a>

<li> (1-16) <a href="slides/L2-Agents.pdf">L2-Agents.pdf</a>, 
            <a href="slides/Sudoku-hardest.pdf">Sudoku-hardest.pdf</a>

<li> (1-23) <a href="slides/L3-State-spaces.pdf">L3-State-spaces.pdf</a>, 
            <a href="slides/Sudoku-evil.pdf">Sudoku-evil.pdf</a>

<li> (1-28) <a href="slides/L4-Informed-search.pdf">L4-Informed-search.pdf</a>

<li> (1-30) <a href="slides/L5-CSP+qsim-6up.pdf">L5-CSP+qsim-6up.pdf</a>

<li> (2-4, 2-6)  <a href="slides/L6+L7-Logical Agents.pdf">L6+L7-Logical Agents.pdf</a>

<li> (2-11) <a href="slides/L8-First-order-logic.pdf">L8-First-order-logic.pdf</a>

<li> (2-13) <a href="slides/L9-First-order-inference.pdf">L9-First-order-inference.pdf</a>

<li> (2-18) <a href="slides/L10-Representing-knowledge.pdf">L10-Representing-knowledge.pdf</a>

<li> (2-25, 2-27) <a href="slides/L11+L12-Planning.pdf">L11+L12-Planning.pdf</a>

<li> (3-3) <a href="slides/L13-Real-World-Planning.pdf">L13-Real-World-Planning.pdf</a>

<li> (3-17) <a href="slides/L14-Uncertainty.pdf">L14-Uncertainty.pdf</a>

<li> (3-19) <a href="slides/L15-Bayes-networks.pdf">L15-Bayes-networks.pdf</a>

<li> (3-26) <a href="slides/L16-Bayes-inference.pdf">L16-Bayes-inference.pdf</a>

<li> (3-31) <a href="slides/L17-Decision-analysis.pdf">L17-Decision-analysis.pdf</a>

<li> (4-2) <a href="slides/L18-Learning-decision-trees.pdf">L18-Learning-decision-trees.pdf</a>

<li> (4-7) <a href="slides/L19-Statistical-learning.pdf">L19-Statistical-learning.pdf</a>

<li> (4-9) <a href="slides/L20-Kernel-methods.pdf">L20-Kernel-methods.pdf</a>

<li> (4-14) <a href="slides/L21-Reinforcement-learning.pdf">L21-Reinforcement-learning.pdf</a>

<li> (4-21) <a href="slides/L22-Robot-learning.pdf">L22-Robot-learning.pdf</a>

<li> (4-28) <a href="slides/L23-Is-AI-possible.pdf">L23-Is-AI-possible.pdf</a>

<li> (4-30) <a href="slides/L24-What-if-we-succeed.pdf">L24-What-if-we-succeed.pdf</a>

</ul>



<h2>Additional Handout Readings</h2>

<ul>

<li> <a href="readings/Newell+Simon-cacm-76.pdf">
     Computer Science as Empirical Inquiry:  Symbols and Search</a>,
     Newell and Simon, CACM, 1976.

<li> <a href="readings/Sudoku-sciam-06.pdf">The Science of SudoKu</a>,
     Scientific American, 2006.

<li> <a href="http://www.abelard.org/turpap/turpap.html">
     Computing Machines and Intelligence</a>, Alan Turing, 1950.

</ul>


<hr>

<h4>Code of Conduct</h4>

The Computer Science Department has a Code of Conduct that describes
the obligations of faculty and students.  Read it at
<a href="http://www.cs.utexas.edu/users/ear/CodeOfConduct.html">
http://www.cs.utexas.edu/users/ear/CodeOfConduct.html</a>. <p>


<hr>
<address><a href="/users/kuipers">BJK</a></address>


</body>
</html>
